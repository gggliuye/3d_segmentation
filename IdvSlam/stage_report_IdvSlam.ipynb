{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The tests of IvdSlam, Loop-closure, and Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. visualize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "FileList = glob.glob('F:/pfe_2/realsense/frames/rgb/*.npy')\n",
    "i = 0\n",
    "k = 0\n",
    "bar = progressbar.ProgressBar(maxval=len(FileList), \\\n",
    "            widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "for imagef in FileList:\n",
    "    image = np.load(imagef)\n",
    "    cv2.imwrite('rgb/'+str(i).zfill(3)+'.jpg', image)\n",
    "    bar.update(k+1)\n",
    "    k += 1\n",
    "    i += 1\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/imgs.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loop closure detection test\n",
    "use the bag-of-words algorithm to detect (some functions are from opencv open source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LoopClosure import LoopClosure\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 init by training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- start training ---\n",
      "--- train finished ---\n"
     ]
    }
   ],
   "source": [
    "# init class\n",
    "loopclosure = LoopClosure()\n",
    "\n",
    "FileList = glob.glob('F:/pfe_2/realsense/frames/rgb/*.npy')\n",
    "# train the bag of words by the images of the file list\n",
    "loopclosure.set_vocabulary_by_train(FileList)\n",
    "# save the vocabulary\n",
    "loopclosure.save_vocabulary('voca.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 init by load trained BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loopclosure = LoopClosure()\n",
    "loopclosure.set_vocabulary('voca.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 if detected loop: True ,   if true with image num:  46\n",
      "69 if detected loop: True ,   if true with image num:  48\n",
      "70 if detected loop: True ,   if true with image num:  46\n",
      "71 if detected loop: True ,   if true with image num:  47\n",
      "72 if detected loop: True ,   if true with image num:  49\n",
      "73 if detected loop: True ,   if true with image num:  51\n",
      "140 if detected loop: True ,   if true with image num:  35\n",
      "141 if detected loop: True ,   if true with image num:  35\n",
      "142 if detected loop: True ,   if true with image num:  35\n",
      "145 if detected loop: True ,   if true with image num:  35\n",
      "146 if detected loop: True ,   if true with image num:  35\n",
      "147 if detected loop: True ,   if true with image num:  35\n",
      "148 if detected loop: True ,   if true with image num:  35\n"
     ]
    }
   ],
   "source": [
    "# to reset the image signatures\n",
    "loopclosure.image_signatures = []\n",
    "for i in range(150):\n",
    "    image = np.load('F:/pfe_2/realsense/frames/rgb/'+str(i).zfill(3)+'.npy')\n",
    "    inp = loopclosure.get_signature(image)\n",
    "    \n",
    "    d, n = loopclosure.loop_closure_detection(inp, i, 0.07, 20)\n",
    "    #print(i,'if detected loop:', d, ',   if true with image num: ',n )\n",
    "    if d :\n",
    "        print(i,'if detected loop:', d, ',   if true with image num: ',n )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normal SLAM test\n",
    "this is the tracking part of the slam\n",
    "1.  take keyframes\n",
    "2.  detect feature points (SURF here)\n",
    "3.  match the feature points (Flann matcher)\n",
    "4.  calculate transformation matrix (for rigid body)\n",
    "5.  tracking the camera poisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IdvSlam import IdvSlam\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'F:/pfe_2/realsense/frames'\n",
    "# doc is the dictonary of the input images\n",
    "# and the second input for the class is '', which is the location to create the output files\n",
    "slam = IdvSlam(doc, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the parameter of feature marching\n",
    "slam.set_match_param(0.7)\n",
    "# reset the slam (reset the tracking camera position)\n",
    "slam.reset_Ms()\n",
    "# calculate from the 50th image and for 150 images\n",
    "slam.calculate_for_n_images(150, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "# make the points cloud ply file for visualize\n",
    "slam.make_ply(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slam result with out loop closing\n",
    "\n",
    "beginning from the entrance door (blue cycle) and end with the same door (in red cycle), but because of the accumaltion of error, the door at the beginning and at the end are seperated.\n",
    "\n",
    "\n",
    "![title](img/non_cl_1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loop closure Slam test\n",
    "add the loop closure in Test 1 to the normal Slam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IdvLoopSlam import IdvLoopSlam\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import winsound\n",
    "duration = 1000  # millisecond\n",
    "freq = 440  # Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 define with training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- start training ---\n",
      "--- train finished ---\n"
     ]
    }
   ],
   "source": [
    "doc = 'F:/pfe_2/realsense/frames'\n",
    "slam = IdvLoopSlam(doc, '')\n",
    "FileList = glob.glob('F:/pfe_2/parking/loop_closure/*.npy')\n",
    "slam.set_vocabulary_by_train(FileList)\n",
    "file_dictionary = 'voca.npy'\n",
    "slam.loopclosure.save_vocabulary(file_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2  define with old trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'F:/pfe_2/realsense/frames'\n",
    "slam = IdvLoopSlam(doc, '')\n",
    "slam.set_vocabulary('voca.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3  main process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128 image correction of matrix with image 5: ◢                                 \n",
      "129 image correction of matrix with image 5: ◢                                 \n",
      "133 image correction of matrix with image 10: ◢                                \n",
      "136 image correction of matrix with image 13: ◢                                \n",
      "137 image correction of matrix with image 13: ◢                                \n",
      "138 image correction of matrix with image 14: ◢                                \n",
      "139 image correction of matrix with image 15: ◢                                \n",
      "140 image correction of matrix with image 17: ◢                                \n",
      "141 image correction of matrix with image 18: ◢                                \n",
      "142 image correction of matrix with image 17: ◢                                \n",
      "143 image correction of matrix with image 17: ◢                                \n",
      "144 image correction of matrix with image 19: ◢                                \n",
      "145 image correction of matrix with image 19: ◢                                \n",
      "146 image correction of matrix with image 19: ◢                                \n",
      "147 image correction of matrix with image 19: ◢                                \n",
      "148 image correction of matrix with image 22: ◢                                \n",
      "149 image correction of matrix with image 24: ◢                                \n",
      "150 image correction of matrix with image 26: ◢                                \n",
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- camera drawn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the parameter of feature matching\n",
    "slam.set_match_param(0.7)\n",
    "slam.reset_Ms()\n",
    "# set the maximum image of refine when detecting loop\n",
    "slam.set_max_image(100)\n",
    "# set the range for not take in to count when detect loop closure\n",
    "slam.set_loop_detect_range(20)\n",
    "# calculate from the 50th image and for 150 images\n",
    "slam.calculate_for_n_images(150, 50)\n",
    "# draw all the camera position\n",
    "slam.draw_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "slam.make_ply(10) \n",
    "#winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the result with loop closure\n",
    "![title](img/pts_cl.PNG)\n",
    "\n",
    "the loop is closed compared with the upper result.\n",
    "as the \"two\" doors become one single door (same for the sofas)\n",
    "![title](img/with_cl.PNG)\n",
    "![title](img/lp0.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3*. Loop closure Slam new test plus\n",
    "take a new map from the entrance to our office. (upper test only had the map of entrance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/lpslam_test2_v2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3*.1 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IdvLoopSlam import IdvLoopSlam\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import winsound\n",
    "duration = 1000  # millisecond\n",
    "freq = 440  # Hz\n",
    "doc = 'F:/pfe_2/realsense/frames'\n",
    "slam = IdvLoopSlam(doc, '')\n",
    "slam.set_vocabulary('voca.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- camera drawn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the parameter of feature matching\n",
    "slam.set_match_param(0.75)\n",
    "slam.set_ransacThreshold(5)\n",
    "slam.set_solve_method(0)\n",
    "slam.reset_Ms()\n",
    "# set the maximum image of refine when detecting loop\n",
    "slam.set_max_image(700)\n",
    "# set the range for not take in to count when detect loop closure\n",
    "slam.set_loop_detect_range(500)\n",
    "slam.set_loop_detect_range_max(700)\n",
    "slam.set_loop_detect_seuil(0.08)\n",
    "# calculate from the 50th image and for 150 images\n",
    "slam.calculate_for_n_images(400, 0)\n",
    "# draw all the camera position\n",
    "slam.draw_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "slam.make_ply(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3*.2 error analysis 2018/08/01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018/08/01 some result may be very bad, possible causes:\n",
    "1.  loop closure not enough\n",
    "2.  matrix error\n",
    "3.  for some images, lack of enough feature points\n",
    "\n",
    "2018/08/01 possible solutions:\n",
    "1. --->  make a tour once get into a new room(new region)\n",
    "2. --->  cannot be very big, and in-evidiable, may by can add a ransac when calculating\n",
    "3. --->  try to take far away view, or try other feature points\n",
    "4. --->  reject outlier with calculating transformation matrix\n",
    "\n",
    "2018/08/02 test result:\n",
    "1. these method can refine the result\n",
    "2. error still remains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3*.3 arror analysis 2018/08/02\n",
    "\n",
    "By analysis the sequence of the images, testing over a lots of data. I tested over different scale, different point of view and different density of images.\n",
    "I found the errors are mainly from the depth error from camera.\n",
    "\n",
    "For an example, I find the errors came from this series of image:\n",
    "![title](img/error_ana1.png)\n",
    "And it is mainly because of this image:\n",
    "(errors shown in red and green cycles)\n",
    "![title](img/error_ana2.png)\n",
    "\n",
    "For most of the cases, the intel realsense camera worked very well. I think this error may came from the fast movement of the camera, or by some other factor.\n",
    "\n",
    "####  possible solution:\n",
    "1.  make sure the camera is stable when taking new data.\n",
    "2.  find a way to detect this error automaticly. Can be the degree if bur of the image, can be corrected by the image neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3*.3 reject the outlier images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/outlier1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Mapping test (with segmentation result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mapping import Mapping\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'F:/pfe_2/realsense/frames'\n",
    "Ms = np.load('IdvSlam/matrix.npy')\n",
    "mapping = Mapping(doc, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping.reset()\n",
    "# imgid is the ids for the image with segmentation outputs\n",
    "imgid = np.array([50,62,69,79,109,119,149,159,169,179,189,198])\n",
    "for i in range(len(imgid)):\n",
    "    idx = imgid[i]-50\n",
    "    mapping.add_keyframe(idx , Ms[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping.draw_Map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "version 1.0 \n",
    "\n",
    "the points of the objects and the bounding box of these objects\n",
    "![title](img/obj_bb.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test with updated continue slam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new version of slam\n",
    "\n",
    "which take one image one time as input,\n",
    "and can create multi loops and detect loop closure to connect these loops (as in real using, the some image without much features may interrupt the whole process).\n",
    "![title](img/slam.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IdvLoopSlam import IdvLoopSlam\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import winsound\n",
    "duration = 1000  # millisecond\n",
    "freq = 440  # Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'F:/pfe_2/realsense/frames'\n",
    "slam = IdvLoopSlam(doc, '')\n",
    "slam.set_vocabulary('voca.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameter of feature matching\n",
    "slam.set_match_param(0.7)\n",
    "slam.reset_Ms()\n",
    "# set the range for not take in to count when detect loop closure\n",
    "slam.set_loop_detect_range(20)\n",
    "for True:\n",
    "    image = \n",
    "    depth = \n",
    "    slam.get_one_keyframe(image, depth)\n",
    "    if :\n",
    "        break\n",
    "# draw all the camera position\n",
    "slam.draw_camera()\n",
    "slam.save_for_mapping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnn\n",
    "[0] Tateno, Keisuke, et al. \"CNN-SLAM: Real-time dense monocular SLAM with learned depth prediction.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Vol. 2. 2017.\n",
    "\n",
    "[1] Kendall, Alex, Matthew Grimes, and Roberto Cipolla. \"Posenet: A convolutional network for real-time 6-dof camera relocalization.\" Proceedings of the IEEE international conference on computer vision. 2015.\n",
    "\n",
    "#### loop closure\n",
    "[0] Angeli, Adrien, et al. \"Fast and incremental method for loop-closure detection using bags of visual words.\" IEEE Transactions on Robotics 24.5 (2008): 1027-1037.\n",
    "\n",
    "[1] Latif, Yasir, César Cadena, and José Neira. \"Robust loop closing over time for pose graph SLAM.\" The International Journal of Robotics Research 32.14 (2013): 1611-1626.\n",
    "\n",
    "[2] Labbe, Mathieu, and Francois Michaud. \"Appearance-based loop closure detection for online large-scale and long-term operation.\" IEEE Transactions on Robotics 29.3 (2013): 734-745.\n",
    "\n",
    "[3] Weinmann, Martin, Boris Jutzi, and Clément Mallet. \"Semantic 3D scene interpretation: a framework combining optimal neighborhood size selection with relevant features.\" ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences 2.3 (2014): 181.\n",
    "\n",
    "[4] Csurka, Gabriella, et al. \"Visual categorization with bags of keypoints.\" Workshop on statistical learning in computer vision, ECCV. Vol. 1. No. 1-22. 2004.\n",
    "\n",
    "#### slam\n",
    "[1] Pankaj, Dhanya S., and Rama Rao Nidamanuri. \"A robust estimation technique for 3D point cloud registration.\" Image Analysis & Stereology 35.1 (2016): 15-28.\n",
    "\n",
    "[2] Labbé, Mathieu, and François Michaud. \"Memory management for real-time appearance-based loop closure detection.\" Intelligent Robots and Systems (IROS), 2011 IEEE/RSJ International Conference on. IEEE, 2011.\n",
    "\n",
    "[3] Zamir, Amir R., et al. \"Generic 3d representation via pose estimation and matching.\" European Conference on Computer Vision. Springer, Cham, 2016.\n",
    "\n",
    "[4] Engel, Jakob, Thomas Schöps, and Daniel Cremers. \"LSD-SLAM: Large-scale direct monocular SLAM.\" European Conference on Computer Vision. Springer, Cham, 2014.\n",
    "\n",
    "[5] Shotton, Jamie, et al. \"Scene coordinate regression forests for camera relocalization in RGB-D images.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2013.\n",
    "\n",
    "#### segmentation\n",
    "[1] Papadakis, Panagiotis, and David Filliat. \"Generic Object Discrimination for Mobile Assistive Robots using Projective Light Diffusion.\" Computer Vision Workshops (WACVW), 2018 IEEE Winter Applications of. IEEE, 2018.\n",
    "\n",
    "[2] Landrieu, Loic, and Martin Simonovsky. \"Large-scale point cloud semantic segmentation with superpoint graphs.\" arXiv preprint arXiv:1711.09869 (2017).\n",
    "\n",
    "[3] Jiang, Hao, and Jianxiong Xiao. \"A linear approach to matching cuboids in RGBD images.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2013.\n",
    "\n",
    "[4] Song, Shuran, et al. \"Semantic scene completion from a single depth image.\" Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on. IEEE, 2017."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.5 tf gpu",
   "language": "python",
   "name": "tensorflow_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
