{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "FileList = glob.glob('F:/pfe_2/realsense/frames/rgb/*.npy')\n",
    "i = 0\n",
    "bar = progressbar.ProgressBar(maxval=len(FileList), \\\n",
    "            widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "for imagef in FileList:\n",
    "    image = np.load(imagef)\n",
    "    cv2.imwrite('rgb/'+str(i).zfill(3)+'.jpg', image)\n",
    "    bar.update(i+1)\n",
    "    i += 1\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/imgs.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loop closure detection test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LoopClosure import LoopClosure\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 init by training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- start training ---\n",
      "--- train finished ---\n"
     ]
    }
   ],
   "source": [
    "# init class\n",
    "loopclosure = LoopClosure()\n",
    "\n",
    "FileList = glob.glob('F:/pfe_2/realsense/frames/rgb/*.npy')\n",
    "# train the bag of words by the images of the file list\n",
    "loopclosure.set_vocabulary_by_train(FileList)\n",
    "# save the vocabulary\n",
    "loopclosure.save_vocabulary('voca.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 init by load trained BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loopclosure = LoopClosure()\n",
    "loopclosure.set_vocabulary('voca.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 if detected loop: True ,   if true with image num:  46\n",
      "69 if detected loop: True ,   if true with image num:  48\n",
      "70 if detected loop: True ,   if true with image num:  46\n",
      "71 if detected loop: True ,   if true with image num:  47\n",
      "72 if detected loop: True ,   if true with image num:  49\n",
      "73 if detected loop: True ,   if true with image num:  51\n",
      "140 if detected loop: True ,   if true with image num:  35\n",
      "141 if detected loop: True ,   if true with image num:  35\n",
      "142 if detected loop: True ,   if true with image num:  35\n",
      "145 if detected loop: True ,   if true with image num:  35\n",
      "146 if detected loop: True ,   if true with image num:  35\n",
      "147 if detected loop: True ,   if true with image num:  35\n",
      "148 if detected loop: True ,   if true with image num:  35\n"
     ]
    }
   ],
   "source": [
    "# to reset the image signatures\n",
    "loopclosure.image_signatures = []\n",
    "for i in range(150):\n",
    "    image = np.load('F:/pfe_2/realsense/frames/rgb/'+str(i).zfill(3)+'.npy')\n",
    "    inp = loopclosure.get_signature(image)\n",
    "    \n",
    "    d, n = loopclosure.loop_closure_detection(inp, i, 0.07, 20)\n",
    "    #print(i,'if detected loop:', d, ',   if true with image num: ',n )\n",
    "    if d :\n",
    "        print(i,'if detected loop:', d, ',   if true with image num: ',n )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normal SLAM test\n",
    "this is the tracking part of the slam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IdvSlam import IdvSlam\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'F:/pfe_2/realsense/frames'\n",
    "# doc is the dictonary of the input images\n",
    "# and the second input for the class is '', which is the location to create the output files\n",
    "slam = IdvSlam(doc, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the parameter of feature marching\n",
    "slam.set_match_param(0.7)\n",
    "# reset the slam (reset the tracking camera position)\n",
    "slam.reset_Ms()\n",
    "# calculate from the 50th image and for 150 images\n",
    "slam.calculate_for_n_images(150, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "# make the points cloud ply file for visualize\n",
    "slam.make_ply(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slam result with out loop closing\n",
    "\n",
    "beginning from the entrance door (blue cycle) and end with the same door (in red cycle), but because of the accumaltion of error, the door at the beginning and at the end are seperated.\n",
    "\n",
    "\n",
    "![title](img/non_cl_1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loop closure Slam test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IdvLoopSlam import IdvLoopSlam\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import winsound\n",
    "duration = 1000  # millisecond\n",
    "freq = 440  # Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define with training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- start training ---\n",
      "--- train finished ---\n"
     ]
    }
   ],
   "source": [
    "doc = 'F:/pfe_2/realsense/frames'\n",
    "slam = IdvLoopSlam(doc, '')\n",
    "FileList = glob.glob('F:/pfe_2/realsense/frames/rgb/*.npy')\n",
    "slam.set_vocabulary_by_train(FileList)\n",
    "file_dictionary = 'voca.npy'\n",
    "slam.loopclosure.save_vocabulary(file_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define with old trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'F:/pfe_2/realsense/frames'\n",
    "slam = IdvLoopSlam(doc, '')\n",
    "slam.set_vocabulary('voca.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128 image correction of matrix with image 5: ◢                                 \n",
      "129 image correction of matrix with image 5: ◢                                 \n",
      "133 image correction of matrix with image 10: ◢                                \n",
      "136 image correction of matrix with image 13: ◢                                \n",
      "137 image correction of matrix with image 13: ◢                                \n",
      "138 image correction of matrix with image 14: ◢                                \n",
      "139 image correction of matrix with image 15: ◢                                \n",
      "140 image correction of matrix with image 17: ◢                                \n",
      "141 image correction of matrix with image 18: ◢                                \n",
      "142 image correction of matrix with image 17: ◢                                \n",
      "143 image correction of matrix with image 17: ◢                                \n",
      "144 image correction of matrix with image 19: ◢                                \n",
      "145 image correction of matrix with image 19: ◢                                \n",
      "146 image correction of matrix with image 19: ◢                                \n",
      "147 image correction of matrix with image 19: ◢                                \n",
      "148 image correction of matrix with image 22: ◢                                \n",
      "149 image correction of matrix with image 24: ◢                                \n",
      "150 image correction of matrix with image 26: ◢                                \n",
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- camera drawn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the parameter of feature matching\n",
    "slam.set_match_param(0.7)\n",
    "slam.reset_Ms()\n",
    "# set the maximum image of refine when detecting loop\n",
    "slam.set_max_image(100)\n",
    "# set the range for not take in to count when detect loop closure\n",
    "slam.set_loop_detect_range(20)\n",
    "# calculate from the 50th image and for 150 images\n",
    "slam.calculate_for_n_images(150, 50)\n",
    "# draw all the camera position\n",
    "slam.draw_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "slam.make_ply(10) \n",
    "#winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the result with loop closure\n",
    "![title](img/pts_cl.PNG)\n",
    "\n",
    "the loop is closed compared with the upper result.\n",
    "as the \"two\" doors become one single door (same for the sofas)\n",
    "![title](img/with_cl.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Mapping test (with segmentation result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mapping import Mapping\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'F:/pfe_2/realsense/frames'\n",
    "Ms = np.load('IdvSlam/matrix.npy')\n",
    "mapping = Mapping(doc, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping.reset()\n",
    "# imgid is the ids for the image with segmentation outputs\n",
    "imgid = np.array([50,62,69,79,109,119,149,159,169,179,189,198])\n",
    "for i in range(len(imgid)):\n",
    "    idx = imgid[i]-50\n",
    "    mapping.add_keyframe(idx , Ms[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping.draw_Map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "version 1.0 \n",
    "\n",
    "the points of the objects and the bounding box of these objects\n",
    "![title](img/obj_bb.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test with updated continue slam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new version of slam\n",
    "\n",
    "which take one image one time as input,\n",
    "and can create multi loops and detect loop closure to connect these loops (as in real using, the some image without much features may interrupt the whole process).\n",
    "![title](img/slam.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IdvLoopSlam import IdvLoopSlam\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import winsound\n",
    "duration = 1000  # millisecond\n",
    "freq = 440  # Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'F:/pfe_2/realsense/frames'\n",
    "slam = IdvLoopSlam(doc, '')\n",
    "slam.set_vocabulary('voca.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameter of feature matching\n",
    "slam.set_match_param(0.7)\n",
    "slam.reset_Ms()\n",
    "# set the range for not take in to count when detect loop closure\n",
    "slam.set_loop_detect_range(20)\n",
    "for True:\n",
    "    image = \n",
    "    depth = \n",
    "    slam.get_one_keyframe(image, depth)\n",
    "    if :\n",
    "        break\n",
    "# draw all the camera position\n",
    "slam.draw_camera()\n",
    "slam.save_for_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.5 tf gpu",
   "language": "python",
   "name": "tensorflow_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
